{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Machine Learning on rest brain imaging dataset\n",
    "\n",
    "        1. Using BidsGrabber to understand the data layout\n",
    "        2. Identity Inteface module for iteration on subjects\n",
    "        3. Function for reading path\n",
    "        4. Creating Nodes\n",
    "            1. Function\n",
    "            2. Identity Inteface for iteration\n",
    "            3. Machine learning module\n",
    "        5. Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setting config\n",
    "\n",
    "    setting parameteres values here, so if we need to change value anytime, we can make the changes here, no need to find in the pipeline or functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_input_dir = '/data/NYU/'\n",
    "subjects_info='/data/NYU/participants.tsv'\n",
    "data_output_dir = '/output/'\n",
    "no_of_subjects = 2 #nof of subjects to consider for computation\n",
    "\n",
    "# In participants.tsv file, we have many variables, however we are using participant_id and group\n",
    "subject_id = 'participant_id'\n",
    "group = 'dx_group' # given in file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BidsLayout to easily access the structure of files and filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bids.grabbids import BIDSLayout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layout = BIDSLayout(data_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/NYU/\n",
      "|-- T1w.json\n",
      "|-- participants.tsv\n",
      "|-- phenotypic_NYU.csv\n",
      "|-- sub-0050952\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050952_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050952_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050953\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050953_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050953_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050954\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050954_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050954_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050955\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050955_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050955_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050956\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050956_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050956_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050957\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050957_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050957_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050958\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050958_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050958_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050959\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050959_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050959_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050960\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050960_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050960_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050961\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050961_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050961_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050962\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050962_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050962_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050964\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050964_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050964_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050965\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050965_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050965_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050966\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050966_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050966_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050967\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050967_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050967_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050968\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050968_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050968_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050969\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050969_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050969_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050970\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050970_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050970_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050971\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050971_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050971_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050972\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050972_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050972_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050973\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050973_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050973_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050974\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050974_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050974_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050975\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050975_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050975_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050976\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050976_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050976_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050977\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050977_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050977_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050978\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050978_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050978_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050979\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050979_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050979_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050980\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050980_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050980_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050981\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050981_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050981_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050982\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050982_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050982_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050983\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050983_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050983_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050984\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050984_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050984_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050985\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050985_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050985_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050986\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050986_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050986_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050987\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050987_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050987_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050988\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050988_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050988_task-rest_run-1_bold.nii.gz\n",
      "|-- sub-0050989\n",
      "|   |-- anat\n",
      "|   |   `-- sub-0050989_T1w.nii.gz\n",
      "|   `-- func\n",
      "|       `-- sub-0050989_task-rest_run-1_bold.nii.gz\n",
      "`-- task-rest_bold.json\n",
      "\n",
      "111 directories, 78 files\n"
     ]
    }
   ],
   "source": [
    "!tree $data_input_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0050952', '0050953']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_list = (layout.get_subjects())[0:(no_of_subjects)] #this gives the list of subjects in a given directory\n",
    "subject_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function to get the nifti filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nifti_filenames(subject_id,data_input_dir):\n",
    "#     Remember that all the necesary imports need to be INSIDE the function for the Function Interface to work!\n",
    "    from bids.grabbids import BIDSLayout\n",
    "    \n",
    "    layout = BIDSLayout(data_input_dir)\n",
    "    \n",
    "    func_file_path = [f.filename for f in layout.get(subject=subject_id, type='bold', extensions=['nii', 'nii.gz'])]\n",
    "    \n",
    "    return func_file_path[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing a list of filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_filenames = list()\n",
    "for i , subject_id in enumerate (subject_list):\n",
    "    func_filenames.append(get_nifti_filenames(subject_id, data_input_dir)) \n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### showing all the nifti file name with path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/NYU/sub-0050952/func/sub-0050952_task-rest_run-1_bold.nii.gz',\n",
       " '/data/NYU/sub-0050953/func/sub-0050953_task-rest_run-1_bold.nii.gz']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nifti_images_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  FROM 4-DIMENSIONAL IMAGES TO 2-DIMENSIONAL ARRAY: MASKING\n",
    "    Neuroimaging data are represented in 4 dimensions: 3 spatial dimensions, and one dimension to index time or trials.\n",
    "   \n",
    "    Machine leanrning algorithms,on the other hand, only accept 2-dimensional samples × features matrices\n",
    "   \n",
    "    Depending on the setting, voxels and time series can be considered as features or samples.\n",
    "   \n",
    "    The selected voxels form a brain mask. Such a mask is often given along with the datasets or can be computed with software tools such as FSL or SPM. \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker,MultiNiftiMasker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = list()\n",
    "test_imgs.append('/data/NYU/sub-0050952/func/sub-0050952_task-rest_run-1_bold.nii.gz')\n",
    "test_imgs.append('/data/NYU/sub-0050952/func/sub-0050952_task-rest_run-1_bold.nii.gz')\n",
    "\n",
    "multi_nifti_masker = MultiNiftiMasker(standardize=True)\n",
    "fmri_masked = multi_nifti_masker.fit_transform(test_imgs) \n",
    "# fmri_masked = list of ndarray of each subject and each ndarray represents timeseries * selected voxels from brain mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA PREPARATION: \n",
    "    For the machine learning settings, we need a data matrix, that we will denote X, and optionally a target    variable to predict, y\n",
    "   \n",
    "    X = timeseries * voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.concatenate(fmri_masked, axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 132240)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading subjects meta data and will form the (subject_id - group)\n",
    "  With pandas library , we load tsv file into data frame , and then select the selected columns form this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "subjects_meta_data=pd.read_csv(subjects_info,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extracting subject_id, group that is given in subject_list\n",
    "   1. preparing mask to select the selected subject_id\n",
    "   2. using that mask to select the participant_id , dx_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=subjects_meta_data[subject_id].isin(subject_list) # check setting config for subject_id\n",
    "subject_id_group = subjects_meta_data[mask][[subject_id,group]] # check setting config for group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>dx_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50952</td>\n",
       "      <td>Autism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50953</td>\n",
       "      <td>Autism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id dx_group\n",
       "0           50952   Autism\n",
       "1           50953   Autism"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_id_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### there are two groups, Autism  , Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = subject_id_group['dx_group'].values\n",
    "type(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create a labels set with respective no of time points for each subject\n",
    "\n",
    "Setting labels `1` as `Autism` and `0` as `Control`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_set(nifti_files_path,subjects_groups):\n",
    "    \n",
    "    import nibabel as nb\n",
    "    import numpy as np\n",
    "    labels=[]\n",
    "    \n",
    "    for img in nifti_files_path:\n",
    "        img_load = nb.load(img)\n",
    "        labels += img_load.shape[3] * [(1 if subjects_groups[i] =='Autism' else 0)]\n",
    "        \n",
    "    return np.asarray(labels)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we call labels_set , passing parameters values of list of images path and groups_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=labels_set(nifti_images_list,groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying classifier , train and test \n",
    "\n",
    "\n",
    "   we use a Support Vector Classification, with a linear kernel.\n",
    "   1.The svc object is an object that can be fit (or trained) on data with labels, and then predict labels on data without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')\n",
    "print(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Measuring prediction scores using cross-validation\n",
    "   1. The proper way to measure error rates or prediction accuracy is via cross-validation: leaving out some data and testing on it.\n",
    "\n",
    "Scikit-learn has tools to perform cross-validation easier:\n",
    "You can speed up the computation by using n_jobs=-1, which will spread the computation equally across all processors (but might not work under Windows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [360, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-279-267063d5eddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/neuro/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m     \"\"\"\n\u001b[0;32m-> 1560\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/neuro/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/neuro/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [360, 2]"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "cv_scores = cross_val_score(svc, X, labels, cv=5, n_jobs=-1, verbose=10)\n",
    "print(cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
